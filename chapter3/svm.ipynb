{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "# this is for visiualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#this our main library SKLEARN and its required modules\n",
    "from sklearn import datasets, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inbuild dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it's important to know your data\n",
    "#so lets see whats inside digits..\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so first of all we have data array\n",
    "# let's explore it\n",
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# its length\n",
    "len(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., 10., 14.,  8.,  1.,  0.,  0.,  0.,  2., 16., 14.,  6.,\n",
       "        1.,  0.,  0.,  0.,  0., 15., 15.,  8., 15.,  0.,  0.,  0.,  0.,\n",
       "        5., 16., 16., 10.,  0.,  0.,  0.,  0., 12., 15., 15., 12.,  0.,\n",
       "        0.,  0.,  4., 16.,  6.,  4., 16.,  6.,  0.,  0.,  8., 16., 10.,\n",
       "        8., 16.,  8.,  0.,  0.,  1.,  8., 12., 14., 12.,  1.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what's at the last of data array\n",
    "digits.data[1796]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have a look at digits data last element type,shape and size.\n",
    "print(type(digits.data[1796]))\n",
    "print(digits.data[1796].shape)\n",
    "digits.data[1796].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So are size and shape same?\n",
    "# The ans is no\n",
    "\n",
    "# convert the data to a 2d array for viewing purpose\n",
    "\n",
    "temp = digits.data[1796].reshape(8,8)  # 8 * 8 will give 64 again\n",
    "print(temp.shape)\n",
    "temp.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., 10., 14.,  8.,  1.,  0.,  0.],\n",
       "       [ 0.,  2., 16., 14.,  6.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 15., 15.,  8., 15.,  0.,  0.],\n",
       "       [ 0.,  0.,  5., 16., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0., 12., 15., 15., 12.,  0.,  0.],\n",
       "       [ 0.,  4., 16.,  6.,  4., 16.,  6.,  0.],\n",
       "       [ 0.,  8., 16., 10.,  8., 16.,  8.,  0.],\n",
       "       [ 0.,  1.,  8., 12., 14., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how the last element array look's now\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAC9VJREFUeJzt3dGLXOUdxvHncU3Q6OJitSJGXAslIEJNkFBRNE2IxCqJF71IoOKGlvSiFWMLor0p/gOSXhQhRE3AGNFopEhrDbgiQqtNYqwxiUXDBhPUNYRNokKDya8Xc1LSkLpnt/u+O7O/7weGzO7OzvPOhmfec2bOnNcRIQC5XDDdAwBQH8UHEqL4QEIUH0iI4gMJUXwgoa4ovu1ltj+0/ZHtRwpnPWV71Paekjln5V1re9j2Xtsf2H6wcN5Ftt+x/V6T91jJvCazz/a7tl8pndXkjdh+3/Zu2zsKZw3Y3mp7v+19tm8pmDWveUxnLsdtry0SFhHTepHUJ+ljSd+TNFvSe5JuKJh3u6QFkvZUenxXS1rQXO+X9M/Cj8+SLm2uz5L0tqQfFn6Mv5b0rKRXKv1NRyRdUSlrk6SfN9dnSxqolNsn6TNJ15W4/26Y8RdK+igiDkTESUnPSVpRKiwi3pR0tNT9nyfv04jY1Vw/IWmfpGsK5kVEfNl8Oau5FDtKy/ZcSXdL2lAqY7rYvkydieJJSYqIkxExVil+iaSPI+JgiTvvhuJfI+mTs74+pILFmE62ByXNV2cWLpnTZ3u3pFFJ2yOiZN46SQ9LOl0w41wh6TXbO22vKZhzvaQvJD3d7MpssH1JwbyzrZS0pdSdd0PxU7B9qaQXJa2NiOMlsyLiVETcJGmupIW2byyRY/seSaMRsbPE/X+L2yJigaS7JP3S9u2Fci5UZ7fwiYiYL+krSUVfg5Ik27MlLZf0QqmMbij+YUnXnvX13OZ7M4btWeqUfnNEvFQrt9ksHZa0rFDErZKW2x5RZxdtse1nCmX9R0Qcbv4dlbRNnd3FEg5JOnTWFtNWdZ4ISrtL0q6I+LxUQDcU/++Svm/7+uaZbqWkP07zmKaMbauzj7gvIh6vkHel7YHm+sWSlkraXyIrIh6NiLkRMajO/9vrEfHTElln2L7Edv+Z65LulFTkHZqI+EzSJ7bnNd9aImlviaxzrFLBzXypsykzrSLiG9u/kvQXdV7JfCoiPiiVZ3uLpEWSrrB9SNLvIuLJUnnqzIr3SXq/2e+WpN9GxJ8K5V0taZPtPnWe2J+PiCpvs1VylaRtnedTXSjp2Yh4tWDeA5I2N5PSAUmrC2adeTJbKukXRXOatw4AJNINm/oAKqP4QEIUH0iI4gMJUXwgoa4qfuHDL6ctizzyui2vq4ovqeYft+p/JHnkdVNetxUfQAVFDuCxPaOPChocHJzw75w4cUL9/f2TypvM7x09elSXX375pPKOHDky4d/5+uuvNWfOnEnljY6OTvh3Tp8+rQsumNy8derUqUn9Xq+ICI93G4o/CRs3bqyat2jRoqp5tR/funXrquaNjdX6SP30aFN8NvWBhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyTUqvg1l7gCUN64xW9O2vgHdU75e4OkVbZvKD0wAOW0mfGrLnEFoLw2xU+zxBWQxZSdV785cUDtzywDmIQ2xW+1xFVErJe0Xpr5n84Del2bTf0ZvcQVkNG4M37tJa4AlNdqH79Z563UWm8AKuPIPSAhig8kRPGBhCg+kBDFBxKi+EBCFB9IiOIDCU3Zh3Sm02SWtPp/3H///VXzDh48WDVvZGSkah7qY8YHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQm2W0HrK9qjtPTUGBKC8NjP+RknLCo8DQEXjFj8i3pR0tMJYAFTCPj6QEGvnAQlNWfFZOw/oHWzqAwm1eTtvi6S/Sppn+5Dtn5UfFoCS2iyauarGQADUw6Y+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGEZsTaebXXejt27FjVvIGBgap5tdcirP3/V/vv2Y2Y8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpBQm5NtXmt72PZe2x/YfrDGwACU0+ZY/W8k/SYidtnul7TT9vaI2Ft4bAAKabN23qcRsau5fkLSPknXlB4YgHImtI9ve1DSfElvlxgMgDpafyzX9qWSXpS0NiKOn+fnrJ0H9IhWxbc9S53Sb46Il853G9bOA3pHm1f1LelJSfsi4vHyQwJQWpt9/Fsl3Sdpse3dzeXHhccFoKA2a+e9JckVxgKgEo7cAxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QkCOm/rD6mX6s/ooVK6rmvfzyy1Xzatu0aVPVvKGhoap5tUXEuAfcMeMDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgoTZn2b3I9ju232vWznusxsAAlNPmvPr/krQ4Ir5szq//lu0/R8TfCo8NQCFtzrIbkr5svpzVXGb0h3CAma7VPr7tPtu7JY1K2h4RrJ0H9LBWxY+IUxFxk6S5khbavvHc29heY3uH7R1TPUgAU2tCr+pHxJikYUnLzvOz9RFxc0TcPFWDA1BGm1f1r7Q90Fy/WNJSSftLDwxAOW1e1b9a0ibbfeo8UTwfEa+UHRaAktq8qv8PSfMrjAVAJRy5ByRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgoTZH7uEcDz30UNW8Y8eOVc2rbXBwcLqHkA4zPpAQxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhCg+kBDFBxJqXfxmUY13bXOiTaDHTWTGf1DSvlIDAVBP2yW05kq6W9KGssMBUEPbGX+dpIclnS44FgCVtFlJ5x5JoxGxc5zbsXYe0CPazPi3Slpue0TSc5IW237m3Buxdh7QO8YtfkQ8GhFzI2JQ0kpJr0fET4uPDEAxvI8PJDShU29FxBuS3igyEgDVMOMDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0hoRqydt2jRoqp5d9xxR9W81atXV80bGRmpmjc8PFw1b2hoqGrexo0bq+a1wYwPJETxgYQoPpAQxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhFodstucWvuEpFOSvuEU2kBvm8ix+j+KiCPFRgKgGjb1gYTaFj8kvWZ7p+01JQcEoLy2m/q3RcRh29+VtN32/oh48+wbNE8IPCkAPaDVjB8Rh5t/RyVtk7TwPLdh7TygR7RZLfcS2/1nrku6U9Ke0gMDUE6bTf2rJG2zfeb2z0bEq0VHBaCocYsfEQck/aDCWABUwtt5QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSYu28HlD78dVeO6+2wcHB6R7CtGPGBxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEKtim97wPZW2/tt77N9S+mBASin7bH6v5f0akT8xPZsSXMKjglAYeMW3/Zlkm6XNCRJEXFS0smywwJQUptN/eslfSHpadvv2t7QLKzxX2yvsb3D9o4pHyWAKdWm+BdKWiDpiYiYL+krSY+ceyOW0AJ6R5viH5J0KCLebr7eqs4TAYAeNW7xI+IzSZ/Yntd8a4mkvUVHBaCotq/qPyBpc/OK/gFJq8sNCUBprYofEbslse8OzBAcuQckRPGBhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICFHxNTfqT31d/otBgYGasZp7dq1VfNqr51Xe2252mv13XvvvVXzxsbGquZFhMe7DTM+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6Q0LjFtz3P9u6zLsdt1z10DcCUGvecexHxoaSbJMl2n6TDkrYVHheAgia6qb9E0scRcbDEYADUMdHir5S0pcRAANTTuvjNOfWXS3rhf/yctfOAHtF2QQ1JukvSroj4/Hw/jIj1ktZL9T+WC2BiJrKpv0ps5gMzQqviN8tiL5X0UtnhAKih7RJaX0n6TuGxAKiEI/eAhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGESq2d94WkyXxm/wpJR6Z4ON2QRR55tfKui4grx7tRkeJPlu0dEXHzTMsij7xuy2NTH0iI4gMJdVvx18/QLPLI66q8rtrHB1BHt834ACqg+EBCFB9IiOIDCVF8IKF/A2d2oiTfoz9rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets see how the image looks\n",
    "plt.gray() #just for the color of graph background\n",
    "# plt.summer()\n",
    "print(\"label:\",digits.target[1796])\n",
    "plt.matshow(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contains all possible answer\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., 10., 14.,  8.,  1.,  0.,  0.],\n",
       "       [ 0.,  2., 16., 14.,  6.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 15., 15.,  8., 15.,  0.,  0.],\n",
       "       [ 0.,  0.,  5., 16., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0., 12., 15., 15., 12.,  0.,  0.],\n",
       "       [ 0.,  4., 16.,  6.,  4., 16.,  6.,  0.],\n",
       "       [ 0.,  8., 16., 10.,  8., 16.,  8.,  0.],\n",
       "       [ 0.,  1.,  8., 12., 14., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images array in our digits dataset contains same values as in data but \n",
    "# it is already reformmated to a 8 * 8 numpy array\n",
    "digits.images[1796]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "print(\"label:\",digits.target[1796])\n",
    "# plt.matshow(digits.images[1796])\n",
    "plt.imshow(digits.images[1796]) # this can also be used\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplification\n",
    "\n",
    "images = digits.data\n",
    "labels = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's start building our model\n",
    "# 1st divide our model into to parts train and test usally it's a 70% train and 30% test but \n",
    "# depending on coditions it may varry\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(digits.data, labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n",
      "(1257,)\n",
      "(540, 64)\n",
      "(540,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Detail about SVM and it's various parameter](\"https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classifier.predict(x_test[539].reshape(1,-1))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944444444444445"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create our own zero array to see if it recognise other numbers\n",
    "zero = np.array([[ 0.,  0., 0., 1., 5., 5., 1., 0.],\n",
    "                    [ 0.,  1., 15., 15., 15., 15., 1, 0.],\n",
    "                    [ 0.,  1., 15., 0., 0., 14., 1., 0.],\n",
    "                    [ 0.,  1., 15., 0., 0., 14., 1., 0.],\n",
    "                    [ 0.,  1., 15., 0., 0., 15., 1., 0.],\n",
    "                    [ 0.,  0., 15., 0., 0., 15., 0., 0.],\n",
    "                    [ 0.,  0., 15., 15., 15., 15., 0., 0.],\n",
    "                    [ 0.,  0., 5., 5., 5., 5., 0., 0.]])\n",
    "plt.gray()\n",
    "plt.matshow(zero)\n",
    "plt.show()\n",
    "classifier.predict(zero.reshape(1,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
